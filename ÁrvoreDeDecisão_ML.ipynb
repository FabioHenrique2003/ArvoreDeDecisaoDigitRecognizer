{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dFRH50joOaJR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTx5GMFMONNz"
      },
      "outputs": [],
      "source": [
        "# Carregar os dados\n",
        "train_data = pd.read_csv('/content/train.csv') #Caminho do upload de arquivo\n",
        "test_data = pd.read_csv('/content/test.csv') #Caminho do upload de arquivo\n",
        "\n",
        "# Visualizar as primeiras linhas do conjunto de dados de treino\n",
        "print(train_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar as características (pixels) e os rótulos (dígitos)\n",
        "X = train_data.drop(columns='label')\n",
        "y = train_data['label']\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "LjzvCcKXOS-F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o classificador de árvore de decisão\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Treinar o classificador\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "UV1tEBctOUwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões no conjunto de teste\n",
        "test_predictions = clf.predict(test_data)\n",
        "\n",
        "# Visualizar algumas previsões\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(10):\n",
        "    axes[i].imshow(test_data.iloc[i].values.reshape(28, 28), cmap='gray')\n",
        "    axes[i].set_title(f'Pred: {test_predictions[i]}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SrpguKEROY0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões no conjunto de validação\n",
        "y_pred = clf.predict(X_val)\n",
        "\n",
        "# Calcular a acurácia, precisão e recall do modelo\n",
        "# Foi acrescentado outras métricas porém o score utilizado na competição é apenas o da acurácia\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred, average='weighted')\n",
        "recall = recall_score(y_val, y_pred, average='weighted')\n",
        "\n",
        "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')\n",
        "print(f'Precisão do modelo: {precision * 100:.2f}%')\n",
        "print(f'Recall do modelo: {recall * 100:.2f}%')"
      ],
      "metadata": {
        "id": "9c8xl2WYOVu2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}